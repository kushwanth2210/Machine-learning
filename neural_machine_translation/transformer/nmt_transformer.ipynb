{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fymEtQaETsVc",
        "outputId": "2d52c684-50ed-4de6-9b18-ca97c48bdda6"
      },
      "source": [
        "pip install torchtext==0.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.8.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Dsf-Ie5jCV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "movLFR9bZf2V",
        "outputId": "d6c9cab1-6e4b-4135-fff4-95301a2ff8f2"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF2NyI4E5zbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd25f7c-2413-40ed-f999-9426ed9e6f34"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8QNKIk05tIR"
      },
      "source": [
        "spacy_ger = spacy.load(\"de\")\n",
        "spacy_eng = spacy.load(\"en\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aCKjQM75xBP"
      },
      "source": [
        "def tokenize_ger(text):\n",
        "    return [t.text for t in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [t.text for t in spacy_eng.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qTPGH9N5w92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3cdcfc-0aa0-4e29-e3f6-9699935e3ad9"
      },
      "source": [
        "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z65wOnOz58Ga",
        "outputId": "853f2876-e7d1-4bbd-ae8d-df87724164a1"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=(\".de\", \".en\"), fields=(german, english))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biTpfqXAUaty",
        "outputId": "d0bce8d5-1657-450b-f8b5-52ca73c3d7b8"
      },
      "source": [
        "for data in train_data:\n",
        "    print(vars(data)[\"src\"])\n",
        "    print(vars(data)[\"trg\"])\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n",
            "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvoQWo-58bP"
      },
      "source": [
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-M95kMy58JD"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers,\n",
        "                 num_decoder_layers, forward_expansion, p, max_len, device):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_positional_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_positional_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.device = device\n",
        "\n",
        "        self.transformer = nn.Transformer(embedding_size, num_heads, num_encoder_layers, num_decoder_layers, \n",
        "                                          forward_expansion, dropout=p)\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "    \n",
        "    def build_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_len, N = src.shape\n",
        "        trg_seq_len, N = trg.shape\n",
        "        src_positions = (torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, N).to(self.device))\n",
        "        trg_positions = (torch.arange(0, trg_seq_len).unsqueeze(1).expand(trg_seq_len, N).to(self.device))\n",
        "        \n",
        "        src_embedding = self.dropout((self.src_word_embedding(src) + self.src_positional_embedding(src_positions)))\n",
        "        trg_embedding = self.dropout((self.trg_word_embedding(trg) + self.trg_positional_embedding(trg_positions)))\n",
        "        \n",
        "        src_mask = self.build_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_len).to(self.device)\n",
        "\n",
        "        x = self.transformer(src_embedding, trg_embedding, src_key_padding_mask=src_mask, tgt_mask=trg_mask)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uttL_W_26JxD"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 16\n",
        "lr = 3e-4\n",
        "batch_size = 32\n",
        "src_vocab_size = len(german.vocab)\n",
        "trg_vocab_size = len(english.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "p = 0.10\n",
        "max_len = 100\n",
        "forward_expansion = 4\n",
        "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1GaHVQp6Juq",
        "outputId": "ca1c3be3-7b0a-4149-e539-e80978bfdc30"
      },
      "source": [
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUXnpgyl58Dr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64853d66-f1da-431a-d430-f8d7ca3a8147"
      },
      "source": [
        "train_batches, valid_batches, test_batches = BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                   batch_size=batch_size, sort_within_batch=True,\n",
        "                                                                   sort_key=lambda x: len(x.src),\n",
        "                                                                   device=device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN1CPuLxAEl2",
        "outputId": "919d5cad-e0f6-4892-8916-e831e1bde386"
      },
      "source": [
        "for batch in train_batches:\n",
        "    ger = batch.src\n",
        "    eng = batch.trg\n",
        "    print(ger.shape)\n",
        "    print(eng.shape)\n",
        "    break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13, 32])\n",
            "torch.Size([18, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slfOhhZ0AEje"
      },
      "source": [
        "net = Transformer(embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers, \n",
        "                  num_decoder_layers, forward_expansion, p, max_len, device).to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUhskZB1Asz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48407bd4-357b-4b39-aa90-0c21fa6da5f3"
      },
      "source": [
        "net"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (src_word_embedding): Embedding(7855, 512)\n",
              "  (src_positional_embedding): Embedding(100, 512)\n",
              "  (trg_word_embedding): Embedding(5893, 512)\n",
              "  (trg_positional_embedding): Embedding(100, 512)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vD-E1bpAswj"
      },
      "source": [
        "opt = optim.Adam(net.parameters(), lr)\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtasDdTcVeDk"
      },
      "source": [
        "def translate(net, sentence, german, english, device, max_len=50):\n",
        "    if type(sentence) == str:\n",
        "        tokens = [t.text.lower() for t in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [t.lower() for t in sentence]\n",
        "\n",
        "    tokens.insert(0, \"<sos>\")\n",
        "    tokens.append(\"<eos>\")\n",
        "\n",
        "    text2idx = []\n",
        "    for t in tokens:\n",
        "        text2idx.append(german.vocab.stoi[t])\n",
        "    \n",
        "    text_tensor = torch.LongTensor(text2idx)\n",
        "    text_tensor = text_tensor.unsqueeze(1).to(device)\n",
        "\n",
        "    output = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(output).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            p = net(text_tensor, trg_tensor)\n",
        "\n",
        "        pred = p.argmax(2)[-1, :].item()\n",
        "        output.append(pred)\n",
        "        if pred == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    output_text = [english.vocab.itos[idx] for idx in output]\n",
        "    \n",
        "    return output_text[1:]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBS_zd3Y2j3Y"
      },
      "source": [
        "def bleu(data, net, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for d in data:\n",
        "        src = vars(d)[\"src\"]\n",
        "        trg = vars(d)[\"trg\"]\n",
        "\n",
        "        prediction = translate(net, src, german, english, device)\n",
        "        prediction = prediction[:-1]  \n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "       \n",
        "    return bleu_score(outputs, targets)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf9T3nFuWuKm"
      },
      "source": [
        "def save_checkpoint(net, opt, losses, filename):\n",
        "    check_point = {\"net_dict\": net.state_dict(), \"opt_dict\": opt.state_dict(), \"losses\": losses}\n",
        "    torch.save(check_point, filename)\n",
        "    print(\"Checkpoint Saved!\")\n",
        "\n",
        "def load_checkpoint(net, opt, filename):\n",
        "    check_point = torch.load(filename)\n",
        "    net.load_state_dict(check_point[\"net_dict\"])\n",
        "    opt.load_state_dict(check_point[\"opt_dict\"])\n",
        "    losses = check_point[\"losses\"]\n",
        "    print(\"Checkpoint Loaded!\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POj08mQg5c17",
        "outputId": "84b25e19-09f2-4fbf-c2bb-8b21c3f47da5"
      },
      "source": [
        "t = [[['that', 'is', 'a', 'plane', 'and', 'not', 'a', 'bird']]]\n",
        "o = [['that', 'is', 'a', 'plane', 'and', 'not', 'a', 'dog']]\n",
        "bleu_score(o, t)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8408964276313782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-2aRSbmLCr5"
      },
      "source": [
        "text = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen\"\n",
        "english_translation = \"a boat with several men on it is being pulled ashore by a large team of horses\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxlPHAx8aTTv"
      },
      "source": [
        "losses = []"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqItbvtVBAAt",
        "outputId": "bfc8e8da-af01-4fdf-fad1-dea9b5783702"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    for batch in tqdm.tqdm(train_batches, total=len(train_batches)):\n",
        "        X = batch.src.to(device)\n",
        "        y = batch.trg.to(device)\n",
        "\n",
        "        output = net(X, y[:-1, :])\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        y = y[1:].reshape(-1)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss = loss_fn(output, y)\n",
        "        batch_losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1)\n",
        "        opt.step()\n",
        "    \n",
        "    losses.append(np.round(sum(batch_losses)/len(batch_losses), 5))\n",
        "    print(f\" Epoch: {epoch} | Loss: {losses[epoch]:4f}\")\n",
        "\n",
        "    pred_list = translate(net, text, german, english, device, max_len=50)\n",
        "    pred_text = \"\"\n",
        "    for word in pred_list:\n",
        "        pred_text += word + \" \"\n",
        "\n",
        "    print(pred_text)\n",
        "    print(\"\")\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"\")\n",
        "        save_checkpoint(net, opt, losses, f\"checkpoint-{epoch}.pth.tar\")\n",
        "        print(\"\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/907 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "100%|██████████| 907/907 [00:35<00:00, 25.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 3.437530\n",
            "a boat boat several food in a large <unk> of a large <unk> . <eos> \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/907 [00:00<00:57, 15.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Saved!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.62it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Loss: 2.423850\n",
            "a boat with several several <unk> being to a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.54it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 | Loss: 2.032070\n",
            "a boat with several men is being pulled by a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.57it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Loss: 1.785000\n",
            "a boat of several men with several <unk> is being pulled by a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.42it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 | Loss: 1.596080\n",
            "a boat with several men on is being pulled by a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 | Loss: 1.449460\n",
            "a boat with several men are pulled to cross by a large <unk> . <eos> \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/907 [00:00<00:57, 15.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Saved!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.23it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 | Loss: 1.326010\n",
            "a boat with several men pulled by a large <unk> shore . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:36<00:00, 25.16it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 | Loss: 1.223470\n",
            "a boat with several men on top of a large shore of bicycles shore . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.31it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 | Loss: 1.131110\n",
            "a boat with several men on is pulled by a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.25it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 | Loss: 1.051720\n",
            "a boat with several men on getting ready to shore from a large shore . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Loss: 0.984440\n",
            "a boat with several men on it is pulled by a large <unk> bank of dirt . <eos> \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/907 [00:00<00:58, 15.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Saved!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.23it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 | Loss: 0.921470\n",
            "a boat boat with several men pulled on a large <unk> . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.26it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 | Loss: 0.869440\n",
            "a boat with several men pulled is pulled by a large <unk> of pulled . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:36<00:00, 25.11it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 | Loss: 0.816670\n",
            "a boat with several men on a large dock by a large animal . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:35<00:00, 25.33it/s]\n",
            "  0%|          | 0/907 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 | Loss: 0.775400\n",
            "a boat with several men on is pulled by a large firetruck . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 907/907 [00:36<00:00, 25.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 | Loss: 0.734110\n",
            "a boat with several men are pulled up by a large ship . <eos> \n",
            "\n",
            "\n",
            "Checkpoint Saved!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ydOtc_4xEkbi",
        "outputId": "9fa1c915-80d6-4736-cdc7-b82894a51fc7"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxB-IawIH0J",
        "outputId": "f1cda179-517f-45f2-a939-c5a8e7857b44"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IMprzXQLKSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a70d746-4d70-460c-87eb-e813717a6118"
      },
      "source": [
        "score = bleu(test_data, net, german, english, device) * 100\n",
        "print(f\"Bleu Score: {score}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu Score: 32.21848885116025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiKXu2ZWI1Ig"
      },
      "source": [
        "# bleu score interpretation:\n",
        "# 0 - 19: bad translations\n",
        "# 20 - 29: understandable translations\n",
        "# 30 - 39: good translations\n",
        "# 40 - 49: High quality translations\n",
        "# 50 - 60: Very high quality, adequate, and fluent translations\n",
        "# > 60: Quality often better than human"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLpKV8Os_6eI"
      },
      "source": [
        "text1 = \"Ein Mann geht die Straße entlang, während er eine Tasse in der Hand hält\"\n",
        "og_translation1 = \"a man is walking down the street while holding a cup\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnYBhL6osTeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98df5baf-52fe-46bf-cc9b-b68f1bce59b0"
      },
      "source": [
        "pred_list = translate(net, text1, german, english, device)\n",
        "pred_text = \"\"\n",
        "for word in pred_list:\n",
        "    pred_text += word + \" \"\n",
        "\n",
        "print(pred_text)\n",
        "print(\"\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a man is walking down the street holding a cup . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwoeE9WBLRmk"
      },
      "source": [
        "text2 = \"Dieser Affe klettert auf einen Baum\"\n",
        "og_translation2 = \"that monkey is climbing a tree\""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GiMkk62LRjT",
        "outputId": "2f840cf8-5045-4820-a6e7-ba1146f54d11"
      },
      "source": [
        "pred_list = translate(net, text2, german, english, device)\n",
        "pred_text = \"\"\n",
        "for word in pred_list:\n",
        "    pred_text += word + \" \"\n",
        "\n",
        "print(pred_text)\n",
        "print(\"\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this mountain landscape are climbing a tree . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7LoBGhGLjJ1"
      },
      "source": [
        "text3 = \"Dieser Mann rennt zu langsam, um den Bus zu erreichen\"\n",
        "og_translation3 = \"that man is running too slow to catch the bus\""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ZG7xSc8AfO",
        "outputId": "b6e131e0-5231-4912-fd7d-ce291e6e1754"
      },
      "source": [
        "pred_list = translate(net, text3, german, english, device)\n",
        "pred_text = \"\"\n",
        "for word in pred_list:\n",
        "    pred_text += word + \" \"\n",
        "\n",
        "print(pred_text)\n",
        "print(\"\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this man is running to make this bus to reach the bus . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXcDjumuA_-3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL-tWT_a5w7o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}