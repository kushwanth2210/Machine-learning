{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sa_mark2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAoqDSkCvi8-"
      },
      "source": [
        "import torch\r\n",
        "import spacy\r\n",
        "import tqdm\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchtext import data, datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r4iw5ywey5B8",
        "outputId": "ab62dd82-b2bb-48e3-fce3-b0d8af1a7657"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShI0cqIw2mSx"
      },
      "source": [
        "spacy_en = spacy.load(\"en\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJxjjRQq3wt"
      },
      "source": [
        "def get_bigrams(x):\r\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\r\n",
        "    for n_gram in n_grams:\r\n",
        "        x.append(' '.join(n_gram))\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5BILosvnU9"
      },
      "source": [
        "TEXT = data.Field(tokenize=\"spacy\", preprocessing=get_bigrams)\r\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Ny97gSvynJ",
        "outputId": "462bd71f-a9eb-49fc-f760-91efd6cf8fa5"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 24.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buW7jXibmqS0"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=25000)\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJT5Fh3jqnoz",
        "outputId": "5ab74e81-b757-4467-8213-aa03b97f9238"
      },
      "source": [
        "len(TEXT.vocab.stoi), LABEL.vocab.stoi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25002,\n",
              " defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 0, 'pos': 1}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QuHmWJYv3ji",
        "outputId": "225f866b-450b-4c1f-da15-fd2f4e9ed01a"
      },
      "source": [
        "for d in train_data:\r\n",
        "    print(vars(d)[\"text\"])\r\n",
        "    print(vars(d)[\"label\"])\r\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Not', 'sure', 'one', 'can', 'call', 'this', 'an', 'anti', '-', 'war', 'film', ',', 'it', 'shows', 'war', 'at', 'an', 'elite', 'level', '.', 'These', 'are', 'elite', 'troops', 'that', 'know', 'what', 'they', 'are', 'doing', 'and', 'take', 'great', 'pride', 'in', 'it', '.', 'Even', 'when', 'they', 'are', 'pacifist', ',', 'they', 'still', 'enjoy', 'the', 'skill', 'level', 'and', 'defeating', 'their', 'foes', ',', 'even', 'if', 'it', 'does', 'go', 'against', 'being', 'a', 'pacifist', '.', 'The', 'movies', 'is', 'slow', 'and', 'rather', 'uneventful', 'and', 'in', 'many', 'ways', 'is', 'rather', 'tame', 'as', 'war', 'movies', 'go', '-', 'more', 'so', 'by', 'todays', 'standards', ',', 'no', 'body', 'parts', 'flying', 'off', 'as', 'in', 'modern', 'movies', '.', 'It', 'is', 'brutal', 'in', 'other', 'ways', 'though', 'as', 'you', 'see', 'killing', 'at', 'a', 'personal', 'level', '.', 'This', 'is', 'more', 'of', 'a', 'thinking', 'man', \"'s\", 'movie', '.', 'Once', 'you', 'start', 'to', 'watch', 'you', 'do', \"n't\", 'want', 'to', 'miss', 'anything', '.', 'The', 'thoughts', 'of', 'the', 'men', 'in', 'the', 'movie', 'and', 'their', 'interactions', ',', 'is', 'what', 'the', 'movie', 'is', 'about-', 'not', 'the', 'combat', 'itself', 'or', 'a', 'big', 'exciting', 'storyline', '.', 'This', 'maybe', 'called', 'a', 'war', 'triller.<br', '/><br', '/>If', 'you', 'are', 'into', 'the', 'skill', 'of', 'war', ',', 'if', 'you', 'are', 'into', 'reading', 'or', 'seeing', 'programs', 'about', 'the', 'SAS', 'and', 'so', 'on', ',', 'YOU', 'WANT', 'TO', 'WATCH', 'THIS', 'MOVIE!!!!!<br', '/><br', '/>Comparable', 'movies', 'are', 'The', 'Hill', '(', '1965', ')', 'with', 'Sean', 'Connery', ',', '49th', 'Parallel', '(', '1941', ')', 'with', 'an', 'all', 'star', 'cast', ',', 'The', 'Naked', 'and', 'the', 'Dead', '(', '1958', ')', 'with', 'Cliff', 'Robertson', '.', 'All', 'are', 'unusual', 'in', 'their', 'way', 'and', 'show', 'war', 'at', 'a', 'personal', 'level', '.', 'Enjoy', '!', 'pacifist ,', 'it .', 'as in', 'Cliff Robertson', 'doing and', 'what they', 'troops that', 'way and', 'to watch', 'killing at', 'TO WATCH', 'war film', 'movie .', 'a war', 'maybe called', 'and their', 'is brutal', 'can call', 'defeating their', 'though as', 'show war', 'level .', 'thinking man', 'storyline .', 'a big', 'Hill (', ', 49th', 'Parallel (', 'if you', 'of war', 'todays standards', 'men in', 'what the', ', even', 'sure one', 'are The', 'an all', '. It', 'Naked and', '- war', 'go against', 'no body', 'more of', 'a thinking', 'in their', 'interactions ,', '49th Parallel', 'watch you', 'you do', 'are into', 'a pacifist', ') with', 'the movie', 'skill level', 'elite level', 'These are', 'the combat', 'it shows', 'itself or', 'at a', 'Once you', 'movies are', 'the SAS', 'so on', 'movie is', '( 1941', 'their interactions', 'being a', 'standards ,', 'THIS MOVIE!!!!!<br', 'unusual in', 'against being', '. Enjoy', 'is what', '. The', 'miss anything', 'pacifist .', 'is rather', 'with Cliff', 'war ,', '. All', 'flying off', 'and so', '1941 )', 'to miss', 'big exciting', 'an elite', 'is slow', 'The thoughts', 'are elite', 'Enjoy !', 'in other', 'the skill', 'seeing programs', 'reading or', 'called a', 'skill of', 'and the', '/><br />If', 'foes ,', \"n't want\", 'is more', '1965 )', 'want to', 'thoughts of', ', is', ', it', 'Sean Connery', 'MOVIE!!!!!<br /><br', 'combat itself', 'This is', 'shows war', 'by todays', 'take great', 'even if', 'rather tame', '/><br />Comparable', 'Not sure', '. This', 'is about-', 'start to', '/>Comparable movies', \"man 's\", 'when they', ', no', 'they are', 'war movies', 'and in', ', YOU', 'still enjoy', '. These', 'as war', 'YOU WANT', 'a personal', 'off as', 'in the', ', they', '. Once', 'This maybe', 'war at', 'The Hill', 'enjoy the', 'Even when', '/>If you', 'of the', 'All are', 'exciting storyline', 'at an', 'pride in', 'movies is', 'brutal in', 'it does', 'know what', 'other ways', 'war triller.<br', 'if it', 'movie and', 'the men', 'in modern', 'this an', '. Even', 'slow and', 'one can', 'movies go', 'ways though', 'not the', 'you are', 'WATCH THIS', 'into the', 'level and', 'you see', 'WANT TO', 'many ways', 'cast ,', 'more so', 'and take', '- more', 'or a', 'triller.<br /><br', 'call this', 'Robertson .', 'anything .', 'are pacifist', 'rather uneventful', 'into reading', 'are unusual', ', if', 'The movies', 'uneventful and', 'go -', 'as you', 'personal level', 'that know', 'or seeing', 'with an', 'the Dead', '1958 )', 'are doing', 'SAS and', 'their foes', 'see killing', 'tame as', 'The Naked', 'and rather', 'programs about', 'Connery ,', 'does go', '( 1958', 'elite troops', '( 1965', 'body parts', ', The', 'in many', 'you start', 'of a', 'about- not', 'they still', 'modern movies', 'their way', 'and show', 'parts flying', 'all star', 'movies .', 'with Sean', 'film ,', 'an anti', 'in it', \"'s movie\", \"do n't\", 'ways is', 'and defeating', 'on ,', 'Dead (', 'so by', 'It is', 'star cast', 'anti -', 'great pride', 'about the']\n",
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwAgXbU1qnlb"
      },
      "source": [
        "class FastTextNet(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_size, output_size, pad_idx):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_idx)\r\n",
        "        self.fc = nn.Linear(embedding_size, output_size)\r\n",
        "\r\n",
        "    def forward(self, text):\r\n",
        "        embedded = self.embedding(text).permute(1, 0, 2)\r\n",
        "        pooled = F.avg_pool2d(embedded, kernel_size=(embedded.shape[1], 1)).squeeze(1)\r\n",
        "        output = self.fc(pooled)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LpUdYdmqnjR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "epochs = 10\r\n",
        "batch_size = 64\r\n",
        "vocab_size = len(TEXT.vocab)\r\n",
        "embedding_size = 100\r\n",
        "output_size = 1\r\n",
        "pad_idx = TEXT.vocab.stoi[\"<pad>\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMwVOnGpqng8",
        "outputId": "a02134b8-2300-4386-806b-a8bdb2c2afa5"
      },
      "source": [
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DosvT-ulqjk0"
      },
      "source": [
        "train_batches, test_batches = data.BucketIterator.splits((train_data, test_data), batch_size=batch_size, device = device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUAV2Qf4vgs-",
        "outputId": "b00572fc-aee4-4475-f153-9e9a1ec53a96"
      },
      "source": [
        "net = FastTextNet(vocab_size, embedding_size, output_size, pad_idx).to(device)\r\n",
        "net"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FastTextNet(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6XRAU5fv0rb"
      },
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\r\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDjzQ_BsFVuO"
      },
      "source": [
        "def get_accuracy(preds, y):\r\n",
        "    preds = torch.round(torch.sigmoid(preds))\r\n",
        "    correct = (preds == y).float()\r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "\r\n",
        "    return acc"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvh5sWfSFS-7"
      },
      "source": [
        "def loop(net, batches, train):\r\n",
        "    batch_losses = []\r\n",
        "    batch_accs = []\r\n",
        "\r\n",
        "    if train:\r\n",
        "        print(\"Train Loop:\")\r\n",
        "        net.train()\r\n",
        "        for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "            texts = batch.text.to(device)\r\n",
        "            labels = batch.label.to(device)\r\n",
        "\r\n",
        "            preds = net(texts)\r\n",
        "            preds = preds.squeeze(1)\r\n",
        "\r\n",
        "            loss = loss_fn(preds, labels)\r\n",
        "            acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "            opt.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            opt.step()\r\n",
        "\r\n",
        "            batch_losses.append(loss.item())\r\n",
        "            batch_accs.append(acc)\r\n",
        "\r\n",
        "    else:\r\n",
        "        print(\"Inference Loop:\")\r\n",
        "        net.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "                texts = batch.text.to(device)\r\n",
        "                labels = batch.label.to(device)\r\n",
        "\r\n",
        "                preds = net(texts)\r\n",
        "                preds = preds.squeeze(1)\r\n",
        "\r\n",
        "                loss = loss_fn(preds, labels)\r\n",
        "                acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "                batch_losses.append(loss.item())\r\n",
        "                batch_accs.append(acc) \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"\")\r\n",
        "    \r\n",
        "    return sum(batch_losses) / len(batch_losses), sum(batch_accs) / len(batch_accs)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fPCpopJ2iOW"
      },
      "source": [
        "def predict_sentiment(net, text):\r\n",
        "    net.eval()\r\n",
        "    tokens = get_bigrams([t.text for t in spacy_en.tokenizer(text)])\r\n",
        "    indices = [TEXT.vocab.stoi[t] for t in tokens]\r\n",
        "    indices = torch.LongTensor(indices).unsqueeze(1).to(device)\r\n",
        "    \r\n",
        "    preds = net(indices)\r\n",
        "    preds = torch.sigmoid(preds)\r\n",
        "    \r\n",
        "    print(f\"sentiment: {preds.item()}\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIND6JYy5C8H"
      },
      "source": [
        "text = \"this is a very good idea\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyG5t60WCEfO",
        "outputId": "5b42a824-5996-4764-e8e8-345dd13e3dcb"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    train_loss, train_acc = loop(net, train_batches, True)\r\n",
        "    val_loss, val_acc = loop(net, test_batches, False)\r\n",
        "    \r\n",
        "    print(f\"epoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")\r\n",
        "    predict_sentiment(net, text)\r\n",
        "    print(\"\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:12<00:00, 32.50it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 224.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 80.74it/s]\n",
            "  1%|          | 3/391 [00:00<00:13, 28.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 0 | train_loss: 0.6871 | train_acc: 0.6010 | val_loss: 0.6290 | val_acc: 0.6974\n",
            "sentiment: 0.6498771905899048\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 34.24it/s]\n",
            "  6%|▌         | 22/391 [00:00<00:01, 215.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.90it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 24.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 1 | train_loss: 0.6391 | train_acc: 0.7556 | val_loss: 0.4822 | val_acc: 0.7726\n",
            "sentiment: 0.9837432503700256\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 34.02it/s]\n",
            "  6%|▌         | 24/391 [00:00<00:01, 233.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.59it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 26.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 2 | train_loss: 0.5501 | train_acc: 0.8133 | val_loss: 0.4072 | val_acc: 0.8179\n",
            "sentiment: 0.9999942779541016\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.26it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 229.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.30it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 25.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 3 | train_loss: 0.4657 | train_acc: 0.8538 | val_loss: 0.3866 | val_acc: 0.8478\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.75it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 222.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.65it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 24.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 4 | train_loss: 0.3999 | train_acc: 0.8758 | val_loss: 0.3885 | val_acc: 0.8644\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.88it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 226.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.52it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 27.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 5 | train_loss: 0.3512 | train_acc: 0.8902 | val_loss: 0.4109 | val_acc: 0.8709\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.78it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 228.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 85.51it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 25.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 6 | train_loss: 0.3181 | train_acc: 0.9004 | val_loss: 0.4174 | val_acc: 0.8803\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 34.12it/s]\n",
            "  6%|▌         | 24/391 [00:00<00:01, 235.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.30it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 26.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 7 | train_loss: 0.2890 | train_acc: 0.9077 | val_loss: 0.4345 | val_acc: 0.8849\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.24it/s]\n",
            "  6%|▌         | 22/391 [00:00<00:01, 218.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 84.25it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 26.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 8 | train_loss: 0.2679 | train_acc: 0.9139 | val_loss: 0.4525 | val_acc: 0.8879\n",
            "sentiment: 1.0\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:11<00:00, 33.70it/s]\n",
            "  6%|▌         | 23/391 [00:00<00:01, 221.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:04<00:00, 85.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 9 | train_loss: 0.2492 | train_acc: 0.9188 | val_loss: 0.4710 | val_acc: 0.8914\n",
            "sentiment: 1.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjT0HkDbOZk8"
      },
      "source": [
        "def save_checkpoint(net, opt, filename):\r\n",
        "    check_point = {\"net_dict\": net.state_dict(), \"opt_dict\": opt.state_dict()}\r\n",
        "    torch.save(check_point, filename)\r\n",
        "    print(\"Checkpoint Saved!\")\r\n",
        "\r\n",
        "def load_checkpoint(net, opt, filename):\r\n",
        "    check_point = torch.load(filename)\r\n",
        "    net.load_state_dict(check_point[\"net_dict\"])\r\n",
        "    opt.load_state_dict(check_point[\"opt_dict\"])\r\n",
        "    losses = check_point[\"losses\"]\r\n",
        "    print(\"Checkpoint Loaded!\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2eci0U-OhHN",
        "outputId": "3367f21e-1b3f-4924-8e6d-d85f891da55d"
      },
      "source": [
        "save_checkpoint(net, opt, \"checkpoint.pth.tar\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJPuHWNqrWo",
        "outputId": "de3d7bef-d9f2-4ca3-a806-a9c5054e259f"
      },
      "source": [
        "predict_sentiment(net, \"this is a very bad idea\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 2.2288126899638883e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCDbVcNgjk7-",
        "outputId": "40782ad6-43d4-407b-8168-2f00e44be5b0"
      },
      "source": [
        "predict_sentiment(net, \"this film is terrible\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTwnPAbkyLtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8b418c-750f-4dfa-83af-4e376fa0f63c"
      },
      "source": [
        "predict_sentiment(net, \"you are terrific\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwUdex1N9kz",
        "outputId": "e109b3ca-7b53-40d6-93de-286ac2f07b4f"
      },
      "source": [
        "predict_sentiment(net, \"that is horrible\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki1w6MlGMsGa",
        "outputId": "1ebe1b87-4a35-4e8e-ba4a-ef67feeb9835"
      },
      "source": [
        "predict_sentiment(net, \"yeet!!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cDCPSS89OIG",
        "outputId": "dfd8e0fa-da42-4292-af19-6fa179f621bf"
      },
      "source": [
        "predict_sentiment(net, \"what are you doing?\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.235542431473732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5owdV53wzKE1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52mh57YnpSUl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}