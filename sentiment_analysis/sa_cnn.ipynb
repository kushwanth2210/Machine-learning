{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sa_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAoqDSkCvi8-"
      },
      "source": [
        "import torch\r\n",
        "import spacy\r\n",
        "import tqdm\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchtext import data, datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShI0cqIw2mSx"
      },
      "source": [
        "spacy_en = spacy.load(\"en\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5BILosvnU9"
      },
      "source": [
        "TEXT = data.Field(tokenize=\"spacy\", batch_first=True)\r\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Ny97gSvynJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8b39b2-6cb0-4268-d7e0-b45fe7555b9a"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 147k/84.1M [00:00<01:05, 1.28MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 68.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYUMmye7wHyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d398598-61e9-4a0b-d5d5-a9a94b04fa9c"
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkdOlXE9vnPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5da516-aceb-4e08-deb5-e0c64c118d6f"
      },
      "source": [
        "for d in train_data:\r\n",
        "    print(vars(d)[\"text\"])\r\n",
        "    print(vars(d)[\"label\"])\r\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Exquisite', 'comedy', 'starring', 'Marian', 'Davies', '(', 'with', 'the', 'affable', 'William', 'Haines', ')', '.', 'Young', 'Peggy', 'arrives', 'in', 'Hollywood', 'seeking', 'stardom', '.', 'Cameo', 'performances', 'showcase', '\"', 'all', 'the', 'stars', 'in', 'MGM', \"'s\", 'heaven', '\"', 'in', 'the', 'famous', 'commissary', 'scene', ',', 'plus', 'lots', 'of', 'vintage', 'film', 'making', 'detail', 'for', 'the', 'scholar', '.', 'Pic', 'also', 'captures', 'for', 'posterity', 'Davies', \"'\", 'famous', ',', 'wickedly', 'sarcastic', 'impersonations', 'of', 'the', 'top', 'stars', 'of', 'the', 'day', '(', 'her', 'Swanson', 'is', 'a', 'beaut!).<br', '/><br', '/>\"Peggy', ',', '\"', 'even', 'catches', 'herself', 'as', 'she', 'encounters', 'the', 'famous', 'star', 'Marian', 'Davies', 'at', 'tennis', ',', 'turns', 'up', 'her', 'nose', 'and', 'comments', ',', '\"', 'Ohh', ',', 'I', 'do', \"n't\", 'like', 'her!\"<br', '/><br', '/>My', 'print', 'was', 'perfect', '.', 'Story', ',', 'direction', ',', 'acting', 'an', 'authentic', 'charm', 'and', 'a', 'must', 'for', 'all', 'silent', 'afficinados', '.']\n",
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31glyWiEwXrB"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=25000)\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpPWoIYXfgMG"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_size, num_filters, filter_sizes, output_size, p, pad_idx):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\r\n",
        "        self.conv_layers = nn.ModuleList([nn.Conv1d(in_channels=embedding_size, out_channels=num_filters, \r\n",
        "                                                    kernel_size=fs) for fs in filter_sizes])\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_size)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "\r\n",
        "    def forward(self, text):\r\n",
        "        embedded = self.embedding(text).permute(0, 2, 1)\r\n",
        "\r\n",
        "        conved_n = [F.relu(conv(embedded)) for conv in self.conv_layers]\r\n",
        "        pooled_n = [F.max_pool1d(conved, kernel_size=conved.shape[2]).squeeze(2) for conved in conved_n]\r\n",
        "\r\n",
        "        pooled = self.dropout(torch.cat(pooled_n, dim=1))\r\n",
        "        output = self.fc(pooled)\r\n",
        "\r\n",
        "        return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_95tb-uDfgIo"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "epochs = 10\r\n",
        "batch_size = 64\r\n",
        "vocab_size = len(TEXT.vocab)\r\n",
        "embedding_size = 100\r\n",
        "num_filters = 100\r\n",
        "filter_sizes = [3, 4, 5]\r\n",
        "output_size = 1\r\n",
        "p = 0.5\r\n",
        "pad_idx = TEXT.vocab.stoi[\"<pad>\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZKXFtqOfgEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251056ef-961d-46f8-ce32-8166c7dd2fe7"
      },
      "source": [
        "device"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wOhbdfBfgBg"
      },
      "source": [
        "train_batches, test_batches = data.BucketIterator.splits((train_data, test_data), batch_size=batch_size, device = device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsr2SDLGinEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0645270f-69ed-417b-aba4-b8c1c3e98fe7"
      },
      "source": [
        "net = Net(vocab_size, embedding_size, num_filters, filter_sizes, output_size, p, pad_idx).to(device)\r\n",
        "net"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embedding): Embedding(25002, 100)\n",
              "  (conv_layers): ModuleList(\n",
              "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
              "    (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6XRAU5fv0rb"
      },
      "source": [
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\r\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDjzQ_BsFVuO"
      },
      "source": [
        "def get_accuracy(preds, y):\r\n",
        "    preds = torch.round(torch.sigmoid(preds))\r\n",
        "    correct = (preds == y).float()\r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "\r\n",
        "    return acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvh5sWfSFS-7"
      },
      "source": [
        "def loop(net, batches, train):\r\n",
        "    batch_losses = []\r\n",
        "    batch_accs = []\r\n",
        "\r\n",
        "    if train:\r\n",
        "        print(\"Train Loop:\")\r\n",
        "        net.train()\r\n",
        "        for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "            texts = batch.text.to(device)\r\n",
        "            labels = batch.label.to(device)\r\n",
        "\r\n",
        "            preds = net(texts)\r\n",
        "            preds = preds.squeeze(1)\r\n",
        "\r\n",
        "            loss = loss_fn(preds, labels)\r\n",
        "            acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "            opt.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            opt.step()\r\n",
        "\r\n",
        "            batch_losses.append(loss.item())\r\n",
        "            batch_accs.append(acc)\r\n",
        "\r\n",
        "    else:\r\n",
        "        print(\"Inference Loop:\")\r\n",
        "        net.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            for batch in tqdm.tqdm(batches, total=len(batches)):\r\n",
        "                texts = batch.text.to(device)\r\n",
        "                labels = batch.label.to(device)\r\n",
        "\r\n",
        "                preds = net(texts)\r\n",
        "                preds = preds.squeeze(1)\r\n",
        "\r\n",
        "                loss = loss_fn(preds, labels)\r\n",
        "                acc = get_accuracy(preds, labels)\r\n",
        "\r\n",
        "                batch_losses.append(loss.item())\r\n",
        "                batch_accs.append(acc) \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"\")\r\n",
        "    \r\n",
        "    return sum(batch_losses) / len(batch_losses), sum(batch_accs) / len(batch_accs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fPCpopJ2iOW"
      },
      "source": [
        "def predict_sentiment(net, text, min_len=5):\r\n",
        "    net.eval()\r\n",
        "    tokens = [t.text for t in spacy_en.tokenizer(text)]\r\n",
        "    if len(tokens) < min_len:\r\n",
        "        tokens += [\"<pad>\"] * (min_len - len(tokens))\r\n",
        "\r\n",
        "    indices = [TEXT.vocab.stoi[t] for t in tokens]\r\n",
        "    indices = torch.LongTensor(indices).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    preds = net(indices)\r\n",
        "    preds = torch.sigmoid(preds)\r\n",
        "    \r\n",
        "    print(f\"sentiment: {preds.item()}\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIND6JYy5C8H"
      },
      "source": [
        "text = \"this is a very good idea\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyG5t60WCEfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0066ed-f9ab-4bf1-d905-2c976d862918"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "    train_loss, train_acc = loop(net, train_batches, True)\r\n",
        "    val_loss, val_acc = loop(net, test_batches, False)\r\n",
        "    \r\n",
        "    print(f\"epoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")\r\n",
        "    predict_sentiment(net, text)\r\n",
        "    print(\"\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.71it/s]\n",
            "  7%|▋         | 29/391 [00:00<00:01, 286.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 152.71it/s]\n",
            "  1%|          | 2/391 [00:00<00:19, 19.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 0 | train_loss: 0.6295 | train_acc: 0.6480 | val_loss: 0.4681 | val_acc: 0.7892\n",
            "sentiment: 0.7283974289894104\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:12<00:00, 30.24it/s]\n",
            "  9%|▉         | 35/391 [00:00<00:01, 344.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 160.71it/s]\n",
            "  1%|          | 3/391 [00:00<00:16, 23.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 1 | train_loss: 0.4759 | train_acc: 0.7688 | val_loss: 0.3873 | val_acc: 0.8316\n",
            "sentiment: 0.8933433890342712\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:12<00:00, 30.24it/s]\n",
            "  9%|▉         | 35/391 [00:00<00:01, 342.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 158.75it/s]\n",
            "  1%|          | 2/391 [00:00<00:19, 19.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 2 | train_loss: 0.4024 | train_acc: 0.8144 | val_loss: 0.3328 | val_acc: 0.8586\n",
            "sentiment: 0.9277836680412292\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.48it/s]\n",
            "  9%|▊         | 34/391 [00:00<00:01, 336.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 159.28it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 24.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 3 | train_loss: 0.3354 | train_acc: 0.8533 | val_loss: 0.3038 | val_acc: 0.8682\n",
            "sentiment: 0.9294244050979614\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.96it/s]\n",
            "  7%|▋         | 29/391 [00:00<00:01, 287.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 159.11it/s]\n",
            "  1%|          | 3/391 [00:00<00:14, 26.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 4 | train_loss: 0.2812 | train_acc: 0.8825 | val_loss: 0.2877 | val_acc: 0.8777\n",
            "sentiment: 0.9237751364707947\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:12<00:00, 30.14it/s]\n",
            "  7%|▋         | 29/391 [00:00<00:01, 284.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 158.10it/s]\n",
            "  1%|          | 3/391 [00:00<00:16, 23.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 5 | train_loss: 0.2293 | train_acc: 0.9063 | val_loss: 0.2859 | val_acc: 0.8799\n",
            "sentiment: 0.9109876751899719\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.94it/s]\n",
            "  8%|▊         | 33/391 [00:00<00:01, 325.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 157.54it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 25.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 6 | train_loss: 0.1832 | train_acc: 0.9268 | val_loss: 0.2972 | val_acc: 0.8802\n",
            "sentiment: 0.9263855218887329\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.87it/s]\n",
            "  9%|▉         | 36/391 [00:00<00:01, 351.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 159.68it/s]\n",
            "  1%|          | 3/391 [00:00<00:15, 24.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 7 | train_loss: 0.1403 | train_acc: 0.9453 | val_loss: 0.3200 | val_acc: 0.8763\n",
            "sentiment: 0.8898522853851318\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.87it/s]\n",
            "  8%|▊         | 30/391 [00:00<00:01, 299.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 157.52it/s]\n",
            "  0%|          | 1/391 [00:00<00:42,  9.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 8 | train_loss: 0.1052 | train_acc: 0.9601 | val_loss: 0.3471 | val_acc: 0.8738\n",
            "sentiment: 0.9050530195236206\n",
            "\n",
            "Train Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 30.02it/s]\n",
            "  9%|▉         | 35/391 [00:00<00:01, 341.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Inference Loop:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:02<00:00, 160.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 9 | train_loss: 0.0789 | train_acc: 0.9705 | val_loss: 0.3788 | val_acc: 0.8735\n",
            "sentiment: 0.8994780778884888\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJPuHWNqrWo",
        "outputId": "98521e78-a0d6-4a1b-8ece-ce266c0188d6"
      },
      "source": [
        "predict_sentiment(net, \"this is a very bad idea\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.08899673819541931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCDbVcNgjk7-",
        "outputId": "77e86baa-47a8-43cc-e83e-7f0c424721ab"
      },
      "source": [
        "predict_sentiment(net, \"this film is terrible\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.034502360969781876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTwnPAbkyLtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8c5d64-28a8-4287-ead5-d5ca05f62672"
      },
      "source": [
        "predict_sentiment(net, \"you are terrific\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.9294814467430115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwUdex1N9kz",
        "outputId": "1ef6a537-ef95-4700-d1e8-d347df2d32c4"
      },
      "source": [
        "predict_sentiment(net, \"that is horrible\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.06200595572590828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki1w6MlGMsGa",
        "outputId": "8bda2ada-704a-4015-b561-611c0317612b"
      },
      "source": [
        "predict_sentiment(net, \"yeet!!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.6045075058937073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cDCPSS89OIG",
        "outputId": "0ae99ac0-692f-4f62-d368-2f2305da3e3e"
      },
      "source": [
        "predict_sentiment(net, \"what are you doing?\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment: 0.49868667125701904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMJAwvimil_o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loYTF-4Ld1gJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}